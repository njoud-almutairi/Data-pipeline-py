

Event Data Pipeline for the Ministry of Media


This project demonstrates a data pipeline designed to extract, transform, and load (ETL) data from the Ministry of Media's API into a data lake on Amazon S3 for further analysis and visualization in Power BI. The pipeline is orchestrated using Apache Airflow.

âšª Features Extraction: Fetch data from APIs provided by the Ministry of Media using Python scripts.

âšª Transformation: Process data for analytical readiness:
- Flatten nested structures.
- Handle missing values.
- Concatenate and organize columns.

âšª Loading: Store the processed data in an Amazon S3 data lake for centralized storage.

ðŸ“Š Visualization: Enable insights through Power BI dashboards.
Tools and Technologies

# Tools and Technologies 
ðŸ”¹ Orchestration: Apache Airflow for scheduling and monitoring tasks.

ðŸ”¹ Programming: Python for ETL operations.

ðŸ”¹ Storage: Amazon S3 as the data lake.
Visualization: Power BI for creating and sharing visual dashboards.



Use the package manager [pip](https://pip.pypa.io/en/stable/) to install foobar.
